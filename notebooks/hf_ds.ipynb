{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87826846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jack/projects/jaximus/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42a8b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grain.python\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import grain\n",
    "\n",
    "def get_dummy_dataset(max_length: int):\n",
    "    batch = (\n",
    "        jax.random.randint(\n",
    "            jax.random.PRNGKey(0),\n",
    "            (max_length,),\n",
    "            0,\n",
    "            max_length,\n",
    "        ),\n",
    "        jax.random.randint(\n",
    "            jax.random.PRNGKey(0),\n",
    "            (max_length,),\n",
    "            0,\n",
    "            max_length,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def generator():\n",
    "        while True:\n",
    "            yield batch\n",
    "\n",
    "    return None, grain.python.IterDataset(generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "971a9da4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class IterDataset with abstract method __iter__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m _, ds = \u001b[43mget_dummy_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mget_dummy_dataset\u001b[39m\u001b[34m(max_length)\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     24\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[43mgrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIterDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Can't instantiate abstract class IterDataset with abstract method __iter__"
     ]
    }
   ],
   "source": [
    "_, ds = get_dummy_dataset(max_length=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e3e7937",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/jaximus/.venv/lib/python3.11/site-packages/grain/_src/python/dataset/dataset.py:791\u001b[39m, in \u001b[36mMapDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DatasetIterator[T]:\n\u001b[32m--> \u001b[39m\u001b[32m791\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_iter_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/jaximus/.venv/lib/python3.11/site-packages/grain/_src/python/dataset/transformations/prefetch.py:91\u001b[39m, in \u001b[36mPrefetchIterDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> dataset.DatasetIterator[T]:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPrefetchDatasetIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_allow_nones\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/jaximus/.venv/lib/python3.11/site-packages/grain/_src/python/dataset/transformations/prefetch.py:110\u001b[39m, in \u001b[36mPrefetchDatasetIterator.__init__\u001b[39m\u001b[34m(self, parent, read_options, allow_nones)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m._map_parent = parent\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28mself\u001b[39m._dataset_length = \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28mself\u001b[39m._read_options = read_options\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m._next_index = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/jaximus/.venv/lib/python3.11/site-packages/grain/_src/python/dataset/transformations/source.py:34\u001b[39m, in \u001b[36mSourceMapDataset.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._source)\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "next(iter(ds))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_ds = load_dataset(\"allenai/c4\", \"realnewslike\", num_proc=4, split=\"train\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94848eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_ds = (\n",
    "    grain.MapDataset.source(hf_ds)\n",
    "    .map(lambda x: {\"tokens\": tokenizer.encode(x[\"text\"], return_tensors=\"np\")[0]})\n",
    ")\n",
    "\n",
    "ds = grain.experimental.ConcatThenSplitIterDataset(\n",
    "    parent=parent_ds,\n",
    "    length_struct={\"tokens\": 1024},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23aeb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import grain\n",
    "from typing import List\n",
    "import numpy as np\n",
    "def get_hf_dataset(\n",
    "        hf_name: List[str],\n",
    "        tokenizer_name: str,\n",
    "        max_length: int,\n",
    "        num_proc: int = 4,\n",
    "        split: str = \"train\",\n",
    "):\n",
    "    hf_ds = load_dataset(*hf_name, split=split, num_proc=num_proc)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    parent_ds = (\n",
    "        grain.MapDataset.source(hf_ds)\n",
    "        .map(lambda x: {\"tokens\": tokenizer.encode(x[\"text\"], return_tensors=\"np\")[0]})\n",
    "        \n",
    "    )\n",
    "\n",
    "    ds = grain.experimental.ConcatThenSplitIterDataset(\n",
    "        parent=parent_ds,\n",
    "        length_struct={\"tokens\": max_length+1},\n",
    "    )\n",
    "\n",
    "    ds = ds.map(lambda x: (x['tokens'][:-1], x['tokens'][1:]))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_hf_dataset(\n",
    "    hf_name=[\"allenai/c4\", \"realnewslike\"],\n",
    "    tokenizer_name=\"gpt2\",\n",
    "    max_length=1024,\n",
    "    num_proc=4,\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "ds = ds.batch(2)\n",
    "\n",
    "for x, y in ds:\n",
    "    print(x[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b48c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_big(n, decimals: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Format large numbers using M (millions), B (billions), and T (trillions).\n",
    "    - Only abbreviates when abs(n) >= 10_000_000.\n",
    "    - 10M<1B  -> M\n",
    "    - 1B<1T   -> B\n",
    "    - >=1T     -> T\n",
    "    - Below 10M: use thousands separators.\n",
    "\n",
    "    Examples:\n",
    "      pretty_big(3_450_000)         -> \"3.45M\"\n",
    "      pretty_big(250_000_000)       -> \"250M\"\n",
    "      pretty_big(1_000_000_000)     -> \"1B\"\n",
    "      pretty_big(3_450_000_000)     -> \"3.45B\"\n",
    "      pretty_big(1_200_000_000_000) -> \"1.2T\"\n",
    "      pretty_big(7_500_000)         -> \"7,500,000\"\n",
    "    \"\"\"\n",
    "    abs_n = abs(n)\n",
    "\n",
    "    # Below 10M: plain formatting with separators\n",
    "    if abs_n < 10_000_000:\n",
    "        if float(n).is_integer():\n",
    "            return f\"{int(n):,}\"\n",
    "        return f\"{n:,.{decimals}f}\".rstrip('0').rstrip('.')\n",
    "\n",
    "    # Choose scale & suffix\n",
    "    if abs_n < 1_000_000_000:\n",
    "        value, suffix = n / 1_000_000, \"M\"\n",
    "    elif abs_n < 1_000_000_000_000:\n",
    "        value, suffix = n / 1_000_000_000, \"B\"\n",
    "    else:\n",
    "        value, suffix = n / 1_000_000_000_000, \"T\"\n",
    "\n",
    "    # Round and trim trailing zeros\n",
    "    s = f\"{round(value, decimals):.{decimals}f}\".rstrip('0').rstrip('.')\n",
    "    if s in {\"-0\", \"-0.\", \"-0.0\"}:\n",
    "        s = \"0\"\n",
    "    return f\"{s}{suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9b72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400,000\n",
      "800,000\n",
      "1,200,000\n",
      "1,600,000\n",
      "2,000,000\n",
      "2,400,000\n",
      "2,800,000\n",
      "3,200,000\n",
      "3,600,000\n",
      "4,000,000\n",
      "4,400,000\n",
      "4,800,000\n",
      "5,200,000\n",
      "5,600,000\n",
      "6,000,000\n",
      "6,400,000\n",
      "6,800,000\n",
      "7,200,000\n",
      "7,600,000\n",
      "8,000,000\n",
      "8,400,000\n",
      "8,800,000\n",
      "9,200,000\n",
      "9,600,000\n",
      "10M\n",
      "10.4M\n",
      "10.8M\n",
      "11.2M\n",
      "11.6M\n",
      "12M\n",
      "12.4M\n",
      "12.8M\n",
      "13.2M\n",
      "13.6M\n",
      "14M\n",
      "14.4M\n",
      "14.8M\n",
      "15.2M\n",
      "15.6M\n",
      "16M\n",
      "16.4M\n",
      "16.8M\n",
      "17.2M\n",
      "17.6M\n",
      "18M\n",
      "18.4M\n",
      "18.8M\n",
      "19.2M\n",
      "19.6M\n",
      "20M\n",
      "20.4M\n",
      "20.8M\n",
      "21.2M\n",
      "21.6M\n",
      "22M\n",
      "22.4M\n",
      "22.8M\n",
      "23.2M\n",
      "23.6M\n",
      "24M\n",
      "24.4M\n",
      "24.8M\n",
      "25.2M\n",
      "25.6M\n",
      "26M\n",
      "26.4M\n",
      "26.8M\n",
      "27.2M\n",
      "27.6M\n",
      "28M\n",
      "28.4M\n",
      "28.8M\n",
      "29.2M\n",
      "29.6M\n",
      "30M\n",
      "30.4M\n",
      "30.8M\n",
      "31.2M\n",
      "31.6M\n",
      "32M\n",
      "32.4M\n",
      "32.8M\n",
      "33.2M\n",
      "33.6M\n",
      "34M\n",
      "34.4M\n",
      "34.8M\n",
      "35.2M\n",
      "35.6M\n",
      "36M\n",
      "36.4M\n",
      "36.8M\n",
      "37.2M\n",
      "37.6M\n",
      "38M\n",
      "38.4M\n",
      "38.8M\n",
      "39.2M\n",
      "39.6M\n",
      "40M\n",
      "40.4M\n",
      "40.8M\n",
      "41.2M\n",
      "41.6M\n",
      "42M\n",
      "42.4M\n",
      "42.8M\n",
      "43.2M\n",
      "43.6M\n",
      "44M\n",
      "44.4M\n",
      "44.8M\n",
      "45.2M\n",
      "45.6M\n",
      "46M\n",
      "46.4M\n",
      "46.8M\n",
      "47.2M\n",
      "47.6M\n",
      "48M\n",
      "48.4M\n",
      "48.8M\n",
      "49.2M\n",
      "49.6M\n",
      "50M\n",
      "50.4M\n",
      "50.8M\n",
      "51.2M\n",
      "51.6M\n",
      "52M\n",
      "52.4M\n",
      "52.8M\n",
      "53.2M\n",
      "53.6M\n",
      "54M\n",
      "54.4M\n",
      "54.8M\n",
      "55.2M\n",
      "55.6M\n",
      "56M\n",
      "56.4M\n",
      "56.8M\n",
      "57.2M\n",
      "57.6M\n",
      "58M\n",
      "58.4M\n",
      "58.8M\n",
      "59.2M\n",
      "59.6M\n",
      "60M\n",
      "60.4M\n",
      "60.8M\n",
      "61.2M\n",
      "61.6M\n",
      "62M\n",
      "62.4M\n",
      "62.8M\n",
      "63.2M\n",
      "63.6M\n",
      "64M\n",
      "64.4M\n",
      "64.8M\n",
      "65.2M\n",
      "65.6M\n",
      "66M\n",
      "66.4M\n",
      "66.8M\n",
      "67.2M\n",
      "67.6M\n",
      "68M\n",
      "68.4M\n",
      "68.8M\n",
      "69.2M\n",
      "69.6M\n",
      "70M\n",
      "70.4M\n",
      "70.8M\n",
      "71.2M\n",
      "71.6M\n",
      "72M\n",
      "72.4M\n",
      "72.8M\n",
      "73.2M\n",
      "73.6M\n",
      "74M\n",
      "74.4M\n",
      "74.8M\n",
      "75.2M\n",
      "75.6M\n",
      "76M\n",
      "76.4M\n",
      "76.8M\n",
      "77.2M\n",
      "77.6M\n",
      "78M\n",
      "78.4M\n",
      "78.8M\n",
      "79.2M\n",
      "79.6M\n",
      "80M\n",
      "80.4M\n",
      "80.8M\n",
      "81.2M\n",
      "81.6M\n",
      "82M\n",
      "82.4M\n",
      "82.8M\n",
      "83.2M\n",
      "83.6M\n",
      "84M\n",
      "84.4M\n",
      "84.8M\n",
      "85.2M\n",
      "85.6M\n",
      "86M\n",
      "86.4M\n",
      "86.8M\n",
      "87.2M\n",
      "87.6M\n",
      "88M\n",
      "88.4M\n",
      "88.8M\n",
      "89.2M\n",
      "89.6M\n",
      "90M\n",
      "90.4M\n",
      "90.8M\n",
      "91.2M\n",
      "91.6M\n",
      "92M\n",
      "92.4M\n",
      "92.8M\n",
      "93.2M\n",
      "93.6M\n",
      "94M\n",
      "94.4M\n",
      "94.8M\n",
      "95.2M\n",
      "95.6M\n",
      "96M\n",
      "96.4M\n",
      "96.8M\n",
      "97.2M\n",
      "97.6M\n",
      "98M\n",
      "98.4M\n",
      "98.8M\n",
      "99.2M\n",
      "99.6M\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1_000_000_00, 400_000):\n",
    "    print(pretty_big(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
