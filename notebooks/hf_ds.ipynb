{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87826846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_ds = load_dataset(\"allenai/c4\", \"realnewslike\", num_proc=4, split=\"train\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94848eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_ds = (\n",
    "    grain.MapDataset.source(hf_ds)\n",
    "    .map(lambda x: {\"tokens\": tokenizer.encode(x[\"text\"], return_tensors=\"np\")[0]})\n",
    ")\n",
    "\n",
    "ds = grain.experimental.ConcatThenSplitIterDataset(\n",
    "    parent=parent_ds,\n",
    "    length_struct={\"tokens\": 1024},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23aeb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import grain\n",
    "from typing import List\n",
    "import numpy as np\n",
    "def get_hf_dataset(\n",
    "        hf_name: List[str],\n",
    "        tokenizer_name: str,\n",
    "        max_length: int,\n",
    "        num_proc: int = 4,\n",
    "        split: str = \"train\",\n",
    "):\n",
    "    hf_ds = load_dataset(*hf_name, split=split, num_proc=num_proc)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    parent_ds = (\n",
    "        grain.MapDataset.source(hf_ds)\n",
    "        .map(lambda x: {\"tokens\": tokenizer.encode(x[\"text\"], return_tensors=\"np\")[0]})\n",
    "        \n",
    "    )\n",
    "\n",
    "    ds = grain.experimental.ConcatThenSplitIterDataset(\n",
    "        parent=parent_ds,\n",
    "        length_struct={\"tokens\": max_length+1},\n",
    "    )\n",
    "\n",
    "    ds = ds.map(lambda x: (x['tokens'][:-1], x['tokens'][1:]))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_hf_dataset(\n",
    "    hf_name=[\"allenai/c4\", \"realnewslike\"],\n",
    "    tokenizer_name=\"gpt2\",\n",
    "    max_length=1024,\n",
    "    num_proc=4,\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "ds = ds.batch(2)\n",
    "\n",
    "for x, y in ds:\n",
    "    print(x[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b48c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_big(n, decimals: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Format large numbers using M (millions), B (billions), and T (trillions).\n",
    "    - Only abbreviates when abs(n) >= 10_000_000.\n",
    "    - 10M<1B  -> M\n",
    "    - 1B<1T   -> B\n",
    "    - >=1T     -> T\n",
    "    - Below 10M: use thousands separators.\n",
    "\n",
    "    Examples:\n",
    "      pretty_big(3_450_000)         -> \"3.45M\"\n",
    "      pretty_big(250_000_000)       -> \"250M\"\n",
    "      pretty_big(1_000_000_000)     -> \"1B\"\n",
    "      pretty_big(3_450_000_000)     -> \"3.45B\"\n",
    "      pretty_big(1_200_000_000_000) -> \"1.2T\"\n",
    "      pretty_big(7_500_000)         -> \"7,500,000\"\n",
    "    \"\"\"\n",
    "    abs_n = abs(n)\n",
    "\n",
    "    # Below 10M: plain formatting with separators\n",
    "    if abs_n < 10_000_000:\n",
    "        if float(n).is_integer():\n",
    "            return f\"{int(n):,}\"\n",
    "        return f\"{n:,.{decimals}f}\".rstrip('0').rstrip('.')\n",
    "\n",
    "    # Choose scale & suffix\n",
    "    if abs_n < 1_000_000_000:\n",
    "        value, suffix = n / 1_000_000, \"M\"\n",
    "    elif abs_n < 1_000_000_000_000:\n",
    "        value, suffix = n / 1_000_000_000, \"B\"\n",
    "    else:\n",
    "        value, suffix = n / 1_000_000_000_000, \"T\"\n",
    "\n",
    "    # Round and trim trailing zeros\n",
    "    s = f\"{round(value, decimals):.{decimals}f}\".rstrip('0').rstrip('.')\n",
    "    if s in {\"-0\", \"-0.\", \"-0.0\"}:\n",
    "        s = \"0\"\n",
    "    return f\"{s}{suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9b72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400,000\n",
      "800,000\n",
      "1,200,000\n",
      "1,600,000\n",
      "2,000,000\n",
      "2,400,000\n",
      "2,800,000\n",
      "3,200,000\n",
      "3,600,000\n",
      "4,000,000\n",
      "4,400,000\n",
      "4,800,000\n",
      "5,200,000\n",
      "5,600,000\n",
      "6,000,000\n",
      "6,400,000\n",
      "6,800,000\n",
      "7,200,000\n",
      "7,600,000\n",
      "8,000,000\n",
      "8,400,000\n",
      "8,800,000\n",
      "9,200,000\n",
      "9,600,000\n",
      "10M\n",
      "10.4M\n",
      "10.8M\n",
      "11.2M\n",
      "11.6M\n",
      "12M\n",
      "12.4M\n",
      "12.8M\n",
      "13.2M\n",
      "13.6M\n",
      "14M\n",
      "14.4M\n",
      "14.8M\n",
      "15.2M\n",
      "15.6M\n",
      "16M\n",
      "16.4M\n",
      "16.8M\n",
      "17.2M\n",
      "17.6M\n",
      "18M\n",
      "18.4M\n",
      "18.8M\n",
      "19.2M\n",
      "19.6M\n",
      "20M\n",
      "20.4M\n",
      "20.8M\n",
      "21.2M\n",
      "21.6M\n",
      "22M\n",
      "22.4M\n",
      "22.8M\n",
      "23.2M\n",
      "23.6M\n",
      "24M\n",
      "24.4M\n",
      "24.8M\n",
      "25.2M\n",
      "25.6M\n",
      "26M\n",
      "26.4M\n",
      "26.8M\n",
      "27.2M\n",
      "27.6M\n",
      "28M\n",
      "28.4M\n",
      "28.8M\n",
      "29.2M\n",
      "29.6M\n",
      "30M\n",
      "30.4M\n",
      "30.8M\n",
      "31.2M\n",
      "31.6M\n",
      "32M\n",
      "32.4M\n",
      "32.8M\n",
      "33.2M\n",
      "33.6M\n",
      "34M\n",
      "34.4M\n",
      "34.8M\n",
      "35.2M\n",
      "35.6M\n",
      "36M\n",
      "36.4M\n",
      "36.8M\n",
      "37.2M\n",
      "37.6M\n",
      "38M\n",
      "38.4M\n",
      "38.8M\n",
      "39.2M\n",
      "39.6M\n",
      "40M\n",
      "40.4M\n",
      "40.8M\n",
      "41.2M\n",
      "41.6M\n",
      "42M\n",
      "42.4M\n",
      "42.8M\n",
      "43.2M\n",
      "43.6M\n",
      "44M\n",
      "44.4M\n",
      "44.8M\n",
      "45.2M\n",
      "45.6M\n",
      "46M\n",
      "46.4M\n",
      "46.8M\n",
      "47.2M\n",
      "47.6M\n",
      "48M\n",
      "48.4M\n",
      "48.8M\n",
      "49.2M\n",
      "49.6M\n",
      "50M\n",
      "50.4M\n",
      "50.8M\n",
      "51.2M\n",
      "51.6M\n",
      "52M\n",
      "52.4M\n",
      "52.8M\n",
      "53.2M\n",
      "53.6M\n",
      "54M\n",
      "54.4M\n",
      "54.8M\n",
      "55.2M\n",
      "55.6M\n",
      "56M\n",
      "56.4M\n",
      "56.8M\n",
      "57.2M\n",
      "57.6M\n",
      "58M\n",
      "58.4M\n",
      "58.8M\n",
      "59.2M\n",
      "59.6M\n",
      "60M\n",
      "60.4M\n",
      "60.8M\n",
      "61.2M\n",
      "61.6M\n",
      "62M\n",
      "62.4M\n",
      "62.8M\n",
      "63.2M\n",
      "63.6M\n",
      "64M\n",
      "64.4M\n",
      "64.8M\n",
      "65.2M\n",
      "65.6M\n",
      "66M\n",
      "66.4M\n",
      "66.8M\n",
      "67.2M\n",
      "67.6M\n",
      "68M\n",
      "68.4M\n",
      "68.8M\n",
      "69.2M\n",
      "69.6M\n",
      "70M\n",
      "70.4M\n",
      "70.8M\n",
      "71.2M\n",
      "71.6M\n",
      "72M\n",
      "72.4M\n",
      "72.8M\n",
      "73.2M\n",
      "73.6M\n",
      "74M\n",
      "74.4M\n",
      "74.8M\n",
      "75.2M\n",
      "75.6M\n",
      "76M\n",
      "76.4M\n",
      "76.8M\n",
      "77.2M\n",
      "77.6M\n",
      "78M\n",
      "78.4M\n",
      "78.8M\n",
      "79.2M\n",
      "79.6M\n",
      "80M\n",
      "80.4M\n",
      "80.8M\n",
      "81.2M\n",
      "81.6M\n",
      "82M\n",
      "82.4M\n",
      "82.8M\n",
      "83.2M\n",
      "83.6M\n",
      "84M\n",
      "84.4M\n",
      "84.8M\n",
      "85.2M\n",
      "85.6M\n",
      "86M\n",
      "86.4M\n",
      "86.8M\n",
      "87.2M\n",
      "87.6M\n",
      "88M\n",
      "88.4M\n",
      "88.8M\n",
      "89.2M\n",
      "89.6M\n",
      "90M\n",
      "90.4M\n",
      "90.8M\n",
      "91.2M\n",
      "91.6M\n",
      "92M\n",
      "92.4M\n",
      "92.8M\n",
      "93.2M\n",
      "93.6M\n",
      "94M\n",
      "94.4M\n",
      "94.8M\n",
      "95.2M\n",
      "95.6M\n",
      "96M\n",
      "96.4M\n",
      "96.8M\n",
      "97.2M\n",
      "97.6M\n",
      "98M\n",
      "98.4M\n",
      "98.8M\n",
      "99.2M\n",
      "99.6M\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1_000_000_00, 400_000):\n",
    "    print(pretty_big(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
